{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original video\n",
    "video = cv2.VideoCapture('videos/road_video.mp4')\n",
    "\n",
    "# will get all frames of a video\n",
    "while True:\n",
    "  # see if video was read and get video frame by frame\n",
    "  read, frame = video.read()\n",
    "\n",
    "  # show each frame of video\n",
    "  if not read:\n",
    "    break;\n",
    "\n",
    "  cv2.imshow('video', frame)\n",
    "\n",
    "  # cancel out of video so it doesn't go infinity\n",
    "  if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition that creates triangle roi of current road\n",
    "def region_of_interest(road, vertices):\n",
    "\n",
    "  # creates black screen with same shape as input road image\n",
    "  # no need to specify dimensions of road image like np.zeros\n",
    "  mask = np.zeros_like(road)\n",
    "\n",
    "  # get number of color channels in image\n",
    "  # (255,) * channels creates a white color matching the image format\n",
    "  # ie. (255,255,255) for RGB and (255,) for grayscale \n",
    "  if len(road.shape) == 3:\n",
    "    match_mask_color = (255,) * road.shape[2]\n",
    "\n",
    "  else:\n",
    "    match_mask_color = 255\n",
    "    \n",
    "  # fill roi with white using to defined vertices\n",
    "  cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "\n",
    "  # fills in the roi with the actual image of the road\n",
    "  # only pixels inside the roi will be shown, everything else is black\n",
    "  masked_image = cv2.bitwise_and(road, mask)\n",
    "  return masked_image\n",
    "\n",
    "height, width, channels = frame.shape\n",
    "\n",
    "roi_vertices = [\n",
    "  (0, height),\n",
    "  (width / 2, height / 2),\n",
    "  (width, height),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale video\n",
    "# Gaussian blurred video\n",
    "# Canny Edge video\n",
    "# Erosion Video --> easier to see lines of roads when thicker than canny edge\n",
    "\n",
    "# store video file as object\n",
    "video = cv2.VideoCapture('videos/road_video.mp4')\n",
    "\n",
    "# will always return true\n",
    "while True:\n",
    "  # gets both the frame and whether the frame is able to be read (bool)\n",
    "  read, frame = video.read() \n",
    "\n",
    "  # check if video can read each frame\n",
    "  if not read:\n",
    "    break;\n",
    "\n",
    "  # convert to grayscale\n",
    "  frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  #convert to gaussian blue\n",
    "  frame_gaussian = cv2.GaussianBlur(frame_grey, (11,11), 0)\n",
    "\n",
    "  # convert to canny edge\n",
    "  lower = 10\n",
    "  upper = 90\n",
    "  frame_canny = cv2.Canny(frame_gaussian, lower, upper)\n",
    "\n",
    "  # convert to dilation / erosion\n",
    "  kernel = np.ones((3,3), np.uint8)\n",
    "  frame_dilation = cv2.dilate(frame_canny, kernel, 1)\n",
    "  frame_erosion = cv2.erode(frame_dilation, kernel, 1)\n",
    "\n",
    "  # only able to stack videos with same color channels and dimensions\n",
    "  # all put in same 1 color channel (grayscale-based)\n",
    "  row1 = np.hstack((frame_grey, frame_gaussian))\n",
    "  row2 = np.hstack((frame_canny, frame_dilation))\n",
    "  stacked = np.vstack((row1, row2))\n",
    "  cv2.imshow('Combined videos', stacked)\n",
    "\n",
    "  # exiting video\n",
    "  if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "# ensures video is no longer available for use\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read video as object\n",
    "video = cv2.VideoCapture('videos/road_video.mp4')\n",
    "\n",
    "# only want the frame and whether it can be read (bool)\n",
    "# purpose is to select roi for ALL frames later on\n",
    "read, frame = video.read()\n",
    "\n",
    "height, width, channels = frame.shape\n",
    "roi_vertices = [\n",
    "  (0, height),\n",
    "  (width / 2, height / 2),\n",
    "  (width, height),\n",
    "]\n",
    "\n",
    "# will always be true\n",
    "while True:\n",
    "  read, frame = video.read()\n",
    "  # frame is able to be read successfully\n",
    "  # basically this allows us to read all the frames, unless there is a false bool\n",
    "  if not read:  \n",
    "    break;  \n",
    "\n",
    "  # roi with grayscale\n",
    "  frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # roi with gaussian blur\n",
    "  frame_gaussian = cv2.GaussianBlur(frame_grey, (11,11), 0)\n",
    "\n",
    "  # roi with canny edge\n",
    "  lower = 10\n",
    "  upper = 90\n",
    "  frame_canny = cv2.Canny(frame_gaussian, lower, upper)\n",
    "\n",
    "  # roi with dilation / erosion\n",
    "  # THIS is most important step for getting best line detection when performing hough line transforms \n",
    "  kernel = np.ones((3,3), np.uint8)\n",
    "  frame_dilation = cv2.dilate(frame_canny, kernel, 1)\n",
    "  frame_erosion = cv2.erode(frame_dilation, kernel, 1)\n",
    "\n",
    "  # after detecting all possible edges, get the edges only within ROI\n",
    "  video_roi = region_of_interest(frame_dilation, np.array([roi_vertices], np.int32))\n",
    "\n",
    "  # get copy of original frame, so we can append detected lines on each frame\n",
    "  # we don't want to display the same frames with lines later when video plays\n",
    "  og_with_lines = np.copy(frame)\n",
    "\n",
    "  # get subset of lines possible through probablistic hough transform\n",
    "  lines = cv2.HoughLinesP(video_roi, 1, np.pi/180, 20, minLineLength=5)\n",
    "\n",
    "  # get dimensions from all lines detected\n",
    "  for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "\n",
    "    # draws the detected lines in red onto original image\n",
    "    cv2.line(og_with_lines, (x1, y1), (x2, y2), (0,0,255), 2)\n",
    "\n",
    "  # display video where original frame and frame with hough lines show together\n",
    "  stacked = np.vstack((frame, og_with_lines))\n",
    "  cv2.imshow('Combined videos', stacked)\n",
    "\n",
    "  # able to quit video\n",
    "  if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "# get out of video and window\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392.0\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "# original video\n",
    "# capture how many frames in video\n",
    "# and how many frames per second\n",
    "video = cv2.VideoCapture('videos/road_video.mp4')\n",
    "frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(frame_count)\n",
    "print(fps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lane_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
